#!/usr/bin/env python3
"""
Dispatcher Inference Demo

Demonstrates the new dispatcher inference features:
1. Handlers declare preferred_dispatcher (no repetition)
2. Function handlers with @stream_handler decorator
3. Backwards compatible with explicit dispatcher specification

This makes the API more AI-friendly - handlers are self-contained
and don't require external configuration.
"""

import asyncio
import numpy as np
import cv2
from streamlib import (
    StreamRuntime,
    Stream,
    StreamHandler,
    stream_handler,
    VideoInput,
    VideoOutput,
    VideoFrame,
)
from streamlib.clocks import TimedTick


# Example 1: Class-based handler with preferred_dispatcher
class PatternGenerator(StreamHandler):
    """Generates test pattern - lightweight, uses asyncio."""

    preferred_dispatcher = 'asyncio'  # Declare once in handler

    def __init__(self, width=640, height=480):
        super().__init__('pattern')
        self.width = width
        self.height = height
        self.outputs['video'] = VideoOutput('video', capabilities=['cpu'])
        self.frame_count = 0

    async def process(self, tick: TimedTick):
        # Simple gradient pattern
        frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
        intensity = int((self.frame_count % 60) * 255 / 60)
        frame[:, :] = [intensity, 100, 200]

        # Add shapes and text to make blur more visible
        # Draw some rectangles
        cv2.rectangle(frame, (50, 100), (150, 200), (255, 255, 255), -1)
        cv2.rectangle(frame, (200, 100), (300, 200), (0, 0, 0), -1)
        cv2.rectangle(frame, (350, 100), (450, 200), (255, 0, 0), -1)

        # Draw some circles
        cv2.circle(frame, (100, 300), 40, (0, 255, 0), -1)
        cv2.circle(frame, (250, 300), 40, (0, 255, 255), -1)
        cv2.circle(frame, (400, 300), 40, (255, 255, 0), -1)

        # Add text (will show blur on edges)
        cv2.putText(
            frame,
            "SHARP TEXT",
            (150, 400),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.5,
            (255, 255, 255),
            3
        )

        self.outputs['video'].write(VideoFrame(
            data=frame,
            timestamp=tick.timestamp,
            frame_number=tick.frame_number,
            width=self.width,
            height=self.height
        ))

        self.frame_count += 1


# Example 2: Function handler with decorator (AI-friendly!)
@stream_handler(
    inputs={'video': VideoInput('video', capabilities=['cpu'])},
    outputs={'video': VideoOutput('video', capabilities=['cpu'])},
    dispatcher='threadpool'  # Blocking cv2.GaussianBlur needs threadpool
)
async def blur_filter(tick, inputs, outputs):
    """
    AI-generated blur filter.

    This function could be generated by an AI agent based on user request.
    The decorator makes it self-contained - no external config needed!
    """
    frame_msg = inputs['video'].read_latest()
    if frame_msg is None:
        return

    # Apply blur (CPU-bound, blocking operation)
    blurred = cv2.GaussianBlur(frame_msg.data, (15, 15), 0)

    outputs['video'].write(VideoFrame(
        data=blurred,
        timestamp=frame_msg.timestamp,
        frame_number=frame_msg.frame_number,
        width=frame_msg.width,
        height=frame_msg.height
    ))


# Example 3: Display handler with explicit preferred_dispatcher
class SimpleDisplay(StreamHandler):
    """Display handler - blocking cv2.imshow needs threadpool."""

    preferred_dispatcher = 'threadpool'  # Declared in handler

    def __init__(self):
        super().__init__('display')
        self.inputs['video'] = VideoInput('video', capabilities=['cpu'])

    async def on_start(self):
        cv2.namedWindow('Dispatcher Inference Demo', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Dispatcher Inference Demo', 640, 480)

    async def process(self, tick: TimedTick):
        frame_msg = self.inputs['video'].read_latest()
        if frame_msg is None:
            return

        frame = frame_msg.data

        # Add text showing dispatcher info
        cv2.putText(
            frame,
            f"Frame: {tick.frame_number}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            (255, 255, 255),
            2
        )
        cv2.putText(
            frame,
            "Dispatcher inference demo",
            (10, 70),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            1
        )

        cv2.imshow('Dispatcher Inference Demo', frame)
        cv2.waitKey(1)

    async def on_stop(self):
        cv2.destroyAllWindows()


async def main():
    print("=" * 70)
    print("DISPATCHER INFERENCE DEMO")
    print("=" * 70)
    print("Demonstrating new features:")
    print("  1. Handlers declare preferred_dispatcher (no repetition)")
    print("  2. Function handlers with @stream_handler decorator")
    print("  3. Backwards compatible with explicit dispatcher")
    print("=" * 70)

    # Create handlers
    pattern = PatternGenerator(width=640, height=480)
    display = SimpleDisplay()

    # Create runtime
    runtime = StreamRuntime(fps=30)

    # NEW: No dispatcher specified - inferred from handlers!
    print("\nAdding streams with inferred dispatchers:")
    print(f"  pattern: {pattern.preferred_dispatcher}")
    print(f"  blur_filter: threadpool (from decorator)")
    print(f"  display: {display.preferred_dispatcher}")

    # Create streams (wraps function handler)
    pattern_stream = Stream(pattern)        # Uses 'asyncio' from handler
    blur_stream = Stream(blur_filter)       # Uses 'threadpool' from decorator
    display_stream = Stream(display)        # Uses 'threadpool' from handler

    runtime.add_stream(pattern_stream)
    runtime.add_stream(blur_stream)
    runtime.add_stream(display_stream)

    # Connect pipeline - access the wrapped handler
    runtime.connect(pattern.outputs['video'], blur_stream.handler.inputs['video'])
    runtime.connect(blur_stream.handler.outputs['video'], display.inputs['video'])

    print("\n✓ All dispatchers inferred correctly!")
    print("✓ Pipeline: pattern → blur_filter (function!) → display")
    print("\nPress Ctrl+C to stop...")
    print("=" * 70)

    # Start
    runtime.start()

    try:
        await asyncio.sleep(3600)
    except KeyboardInterrupt:
        print("\n\nStopping...")

    await runtime.stop()

    print("\n✓ Demo complete!")
    print("✓ All handlers used their preferred dispatchers")
    print("✓ No dispatcher specification needed in Stream() calls")


if __name__ == '__main__':
    asyncio.run(main())
