use streamlib::{Result, StreamRuntime};
use streamlib::{CameraProcessor, DisplayProcessor};
use streamlib::core::{CameraConfig, DisplayConfig, VideoFrame};

#[tokio::main]
async fn main() -> Result<()> {
    println!("=== Camera â†’ Display Pipeline (Handle-Based API) ===\n");

    
    let mut runtime = StreamRuntime::new();

    
    println!("ğŸ“· Adding camera processor...");
    let camera = runtime.add_processor_with_config::<CameraProcessor>(
        CameraConfig {
            device_id: Some("0x11424001bcf2284".to_string()), 
        }
    )?;
    println!("âœ“ Camera added\n");

    
    println!("ğŸ–¥ï¸  Adding display processor...");
    let display = runtime.add_processor_with_config::<DisplayProcessor>(
        DisplayConfig {
            width: 1280,
            height: 720,
            title: Some("streamlib Camera Display".to_string()),
        }
    )?;
    println!("âœ“ Display added\n");

    
    println!("ğŸ”— Connecting camera â†’ display (type-safe handles)...");
    runtime.connect(
        camera.output_port::<VideoFrame>("video"),   
        display.input_port::<VideoFrame>("video"),   
    )?;
    println!("âœ“ Pipeline connected\n");

    // Start pipeline
    println!("â–¶ï¸  Starting pipeline...");
    println!("   Press Ctrl+C to stop\n");
    runtime.start().await?;

    // Run until Ctrl+C
    runtime.run().await?;

    println!("\nâœ“ Pipeline stopped gracefully");

    Ok(())
}
