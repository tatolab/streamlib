// Copyright (c) 2025 Jonathan Fontanez
// SPDX-License-Identifier: BUSL-1.1

use std::path::PathBuf;
use streamlib::core::{
    AudioCaptureConfig, AudioChannelConverterConfig, AudioResamplerConfig, CameraConfig,
    ChannelConversionMode, Mp4WriterConfig, ResamplingQuality,
};
use streamlib::{
    input, output, request_audio_permission, request_camera_permission, AudioCaptureProcessor,
    AudioChannelConverterProcessor, AudioResamplerProcessor, CameraProcessor, Mp4WriterProcessor,
    Result, StreamRuntime,
};

fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    println!("=== Camera + Audio â†’ MP4 Recorder Pipeline ===\n");

    // Create runtime first
    let runtime = StreamRuntime::new()?;

    // Request camera and microphone permissions (must be on main thread)
    println!("ğŸ”’ Requesting camera permission...");
    if !request_camera_permission()? {
        eprintln!("âŒ Camera permission denied!");
        eprintln!("Please grant permission in System Settings â†’ Privacy & Security â†’ Camera");
        return Ok(());
    }
    println!("âœ… Camera permission granted\n");

    println!("ğŸ”’ Requesting microphone permission...");
    if !request_audio_permission()? {
        eprintln!("âŒ Microphone permission denied!");
        eprintln!("Please grant permission in System Settings â†’ Privacy & Security â†’ Microphone");
        return Ok(());
    }
    println!("âœ… Microphone permission granted\n");

    // Determine output path - save in example folder by default
    let output_path = std::env::var("OUTPUT_PATH").unwrap_or_else(|_| {
        // Get example directory (parent of Cargo.toml)
        let manifest_dir = std::env::var("CARGO_MANIFEST_DIR").unwrap_or_else(|_| ".".to_string());
        format!("{}/recording.mp4", manifest_dir)
    });

    println!("ğŸ“¹ Output file: {}\n", output_path);

    println!("ğŸ“· Adding camera processor...");
    let camera = runtime.add_processor(CameraProcessor::Processor::node(CameraConfig {
        device_id: Some("0x1424001bcf2284".to_string()), // Use default camera
        ..Default::default()
    }))?;
    println!("âœ“ Camera added (capturing video)\n");

    println!("ğŸ¤ Adding audio capture processor...");
    let audio_capture =
        runtime.add_processor(AudioCaptureProcessor::Processor::node(AudioCaptureConfig {
            device_id: None, // Use default microphone
        }))?;
    println!("âœ“ Audio capture added (mono @ 24kHz)\n");

    println!("ğŸ”„ Adding audio resampler (24kHz â†’ 48kHz)...");
    let resampler = runtime.add_processor(AudioResamplerProcessor::Processor::node(
        AudioResamplerConfig {
            source_sample_rate: 24000,
            target_sample_rate: 48000,
            quality: ResamplingQuality::High,
        },
    ))?;
    println!("âœ“ Resampler added\n");

    println!("ğŸ›ï¸  Adding channel converter (mono â†’ stereo)...");
    let channel_converter = runtime.add_processor(
        AudioChannelConverterProcessor::Processor::node(AudioChannelConverterConfig {
            mode: ChannelConversionMode::Duplicate,
        }),
    )?;
    println!("âœ“ Channel converter added\n");

    println!("ğŸ’¾ Adding MP4 writer processor...");
    let mp4_writer =
        runtime.add_processor(Mp4WriterProcessor::Processor::node(Mp4WriterConfig {
            output_path: PathBuf::from(&output_path),
            sync_tolerance_ms: Some(16.6),         // ~1 frame at 60fps
            video_codec: Some("avc1".to_string()), // H.264
            video_bitrate: Some(5_000_000),        // 5 Mbps
            audio_codec: Some("aac".to_string()),  // AAC (note: currently using LPCM)
            audio_bitrate: Some(128_000),          // 128 kbps
        }))?;
    println!("âœ“ MP4 writer added (H.264 video + stereo LPCM audio @ 48kHz)\n");

    println!("ğŸ”— Connecting pipeline:");

    println!("   camera.video â†’ mp4_writer.video");
    runtime.connect(
        output::<CameraProcessor::OutputLink::video>(&camera),
        input::<Mp4WriterProcessor::InputLink::video>(&mp4_writer),
    )?;
    println!("   âœ“ Video connected");

    println!("   audio_capture.audio â†’ resampler.audio_in");
    runtime.connect(
        output::<AudioCaptureProcessor::OutputLink::audio>(&audio_capture),
        input::<AudioResamplerProcessor::InputLink::audio_in>(&resampler),
    )?;
    println!("   âœ“ Audio capture â†’ resampler");

    println!("   resampler.audio_out â†’ channel_converter.audio_in");
    runtime.connect(
        output::<AudioResamplerProcessor::OutputLink::audio_out>(&resampler),
        input::<AudioChannelConverterProcessor::InputLink::audio_in>(&channel_converter),
    )?;
    println!("   âœ“ Resampler â†’ channel converter");

    println!("   channel_converter.audio_out â†’ mp4_writer.audio");
    runtime.connect(
        output::<AudioChannelConverterProcessor::OutputLink::audio_out>(&channel_converter),
        input::<Mp4WriterProcessor::InputLink::audio>(&mp4_writer),
    )?;
    println!("   âœ“ Channel converter â†’ MP4 writer\n");

    println!("â–¶ï¸  Starting recording pipeline...");
    println!("   Recording to: {}", output_path);
    println!("   Press Ctrl+C to stop recording\n");

    println!("ğŸ“Š Audio pipeline: mic (mono 24kHz) â†’ resampler (48kHz) â†’ converter (stereo) â†’ MP4");
    println!("ğŸ“Š Video pipeline: camera â†’ MP4");
    println!("ğŸ“Š A/V sync tolerance: 16.6ms (video frames may be dropped/duplicated)\n");

    // start() blocks on macOS standalone (runs NSApplication event loop)
    runtime.start()?;

    println!("\nâœ… Recording stopped");
    println!("âœ… MP4 file finalized: {}", output_path);
    println!("\nğŸ“Š To view sync statistics, check the logs above");
    println!("ğŸ’¡ Play with: ffplay {} or QuickTime Player", output_path);

    Ok(())
}
