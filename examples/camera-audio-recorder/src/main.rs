use std::path::PathBuf;
use streamlib::core::{
    AudioCaptureConfig, AudioChannelConverterConfig, AudioFrame, AudioResamplerConfig,
    CameraConfig, ChannelConversionMode, Mp4WriterConfig, ResamplingQuality, VideoFrame,
};
use streamlib::{
    AudioCaptureProcessor, AudioChannelConverterProcessor, AudioResamplerProcessor,
    CameraProcessor, Mp4WriterProcessor,
};
use streamlib::{Result, StreamRuntime};

fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    println!("=== Camera + Audio â†’ MP4 Recorder Pipeline ===\n");

    // Create runtime first
    let mut runtime = StreamRuntime::new();

    // Request camera and microphone permissions (must be on main thread)
    println!("ğŸ”’ Requesting camera permission...");
    if !runtime.request_camera()? {
        eprintln!("âŒ Camera permission denied!");
        eprintln!("Please grant permission in System Settings â†’ Privacy & Security â†’ Camera");
        return Ok(());
    }
    println!("âœ… Camera permission granted\n");

    println!("ğŸ”’ Requesting microphone permission...");
    if !runtime.request_microphone()? {
        eprintln!("âŒ Microphone permission denied!");
        eprintln!("Please grant permission in System Settings â†’ Privacy & Security â†’ Microphone");
        return Ok(());
    }
    println!("âœ… Microphone permission granted\n");

    // Determine output path - save in example folder by default
    let output_path = std::env::var("OUTPUT_PATH").unwrap_or_else(|_| {
        // Get example directory (parent of Cargo.toml)
        let manifest_dir = std::env::var("CARGO_MANIFEST_DIR").unwrap_or_else(|_| ".".to_string());
        format!("{}/recording.mp4", manifest_dir)
    });

    println!("ğŸ“¹ Output file: {}\n", output_path);

    println!("ğŸ“· Adding camera processor...");
    let camera = runtime.add_processor::<CameraProcessor>(CameraConfig {
        device_id: Some("0x1424001bcf2284".to_string()), // Use default camera
    })?;
    println!("âœ“ Camera added (capturing video)\n");

    println!("ğŸ¤ Adding audio capture processor...");
    let audio_capture =
        runtime.add_processor::<AudioCaptureProcessor>(AudioCaptureConfig {
            device_id: None, // Use default microphone
        })?;
    println!("âœ“ Audio capture added (mono @ 24kHz)\n");

    println!("ğŸ”„ Adding audio resampler (24kHz â†’ 48kHz)...");
    let resampler =
        runtime.add_processor::<AudioResamplerProcessor>(AudioResamplerConfig {
            source_sample_rate: 24000,
            target_sample_rate: 48000,
            quality: ResamplingQuality::High,
        })?;
    println!("âœ“ Resampler added\n");

    println!("ğŸ›ï¸  Adding channel converter (mono â†’ stereo)...");
    let channel_converter = runtime.add_processor::<AudioChannelConverterProcessor>(
        AudioChannelConverterConfig {
            mode: ChannelConversionMode::Duplicate,
        },
    )?;
    println!("âœ“ Channel converter added\n");

    println!("ğŸ’¾ Adding MP4 writer processor...");
    let mp4_writer = runtime.add_processor::<Mp4WriterProcessor>(Mp4WriterConfig {
        output_path: PathBuf::from(&output_path),
        sync_tolerance_ms: Some(16.6),         // ~1 frame at 60fps
        video_codec: Some("avc1".to_string()), // H.264
        video_bitrate: Some(5_000_000),        // 5 Mbps
        audio_codec: Some("aac".to_string()),  // AAC (note: currently using LPCM)
        audio_bitrate: Some(128_000),          // 128 kbps
    })?;
    println!("âœ“ MP4 writer added (H.264 video + stereo LPCM audio @ 48kHz)\n");

    println!("ğŸ”— Connecting pipeline:");
    println!("   camera.video â†’ mp4_writer.video");
    runtime.connect(
        camera.output_port::<VideoFrame>("video"),
        mp4_writer.input_port::<VideoFrame>("video"),
    )?;
    println!("   âœ“ Video connected");

    println!("   audio_capture.audio â†’ resampler.audio_in");
    runtime.connect(
        audio_capture.output_port::<AudioFrame>("audio"),
        resampler.input_port::<AudioFrame>("audio_in"),
    )?;
    println!("   âœ“ Audio capture â†’ resampler");

    println!("   resampler.audio_out â†’ channel_converter.audio_in");
    runtime.connect(
        resampler.output_port::<AudioFrame>("audio_out"),
        channel_converter.input_port::<AudioFrame>("audio_in"),
    )?;
    println!("   âœ“ Resampler â†’ channel converter");

    println!("   channel_converter.audio_out â†’ mp4_writer.audio");
    runtime.connect(
        channel_converter.output_port::<AudioFrame>("audio_out"),
        mp4_writer.input_port::<AudioFrame>("audio"),
    )?;
    println!("   âœ“ Channel converter â†’ MP4 writer\n");

    println!("â–¶ï¸  Starting recording pipeline...");
    println!("   Recording to: {}", output_path);
    println!("   Press Ctrl+C to stop recording\n");

    println!("ğŸ“Š Audio pipeline: mic (mono 24kHz) â†’ resampler (48kHz) â†’ converter (stereo) â†’ MP4");
    println!("ğŸ“Š Video pipeline: camera â†’ MP4");
    println!("ğŸ“Š A/V sync tolerance: 16.6ms (video frames may be dropped/duplicated)\n");

    runtime.start()?;
    runtime.run()?;

    println!("\nâœ… Recording stopped");
    println!("âœ… MP4 file finalized: {}", output_path);
    println!("\nğŸ“Š To view sync statistics, check the logs above");
    println!("ğŸ’¡ Play with: ffplay {} or QuickTime Player", output_path);

    Ok(())
}
