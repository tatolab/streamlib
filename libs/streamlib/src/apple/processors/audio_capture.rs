use crate::core::{AudioFrame, Result, StreamError, StreamOutput};
use streamlib_macros::StreamProcessor;
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use cpal::{Device, Stream, StreamConfig};
use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
use std::sync::Arc;
use parking_lot::Mutex;
use rubato::{Resampler, SincFixedIn, SincInterpolationType, SincInterpolationParameters, WindowFunction};

// Apple-specific configuration and device types
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct AppleAudioCaptureConfig {
    /// Optional device name or ID to capture from. If None, uses default input device.
    pub device_id: Option<String>,
}

impl Default for AppleAudioCaptureConfig {
    fn default() -> Self {
        Self {
            device_id: None,
        }
    }
}

#[derive(Debug, Clone)]
pub struct AppleAudioInputDevice {
    pub id: usize,
    pub name: String,
    pub sample_rate: u32,
    pub channels: u32,
    pub is_default: bool,
}

#[derive(StreamProcessor)]
#[processor(
    mode = Pull,
    description = "Captures mono audio from macOS microphones using CoreAudio - driven by platform audio callback loop",
    unsafe_send
)]
pub struct AppleAudioCaptureProcessor {
    #[output(description = "Captured mono audio frames from the microphone")]
    audio: StreamOutput<AudioFrame<1>>,

    #[config]
    config: AppleAudioCaptureConfig,

    // Runtime state fields - auto-detected (no attribute needed)
    device_info: Option<AppleAudioInputDevice>,
    _device: Option<Device>,
    _stream: Option<Stream>,
    sample_buffer: Arc<Mutex<Vec<f32>>>,
    is_capturing: Arc<AtomicBool>,
    current_level: Arc<Mutex<f32>>,
    frame_counter: Arc<AtomicU64>,
    runtime_sample_rate: u32,
    runtime_buffer_size: usize,
    device_sample_rate: u32,
    device_channels: u16,
    resampler: Arc<Mutex<Option<SincFixedIn<f32>>>>,
    stream_setup_done: bool,
    wakeup_tx: Arc<Mutex<Option<crossbeam_channel::Sender<crate::core::runtime::WakeupEvent>>>>,
}

// SAFETY: cpal::Stream and cpal::Device are not Send, but AppleAudioCaptureProcessor is safe to send
// between threads because cpal handles thread-safety internally via platform audio APIs
// unsafe impl Send auto-generated by StreamProcessor macro with unsafe_send attribute

// Business logic - all trait methods auto-generated by macro!
impl AppleAudioCaptureProcessor {
    // Lifecycle - auto-detected by macro
    fn setup(&mut self, ctx: &crate::core::RuntimeContext) -> Result<()> {
        tracing::info!("[AudioCapture] setup() called - storing runtime config");

        // Store runtime's audio configuration for use in process()
        self.runtime_sample_rate = ctx.audio.sample_rate;
        self.runtime_buffer_size = ctx.audio.buffer_size;
        self.stream_setup_done = false;

        tracing::info!("[AudioCapture] Runtime config: {} Hz, {} samples buffer",
            self.runtime_sample_rate, self.runtime_buffer_size);
        tracing::info!("[AudioCapture] Actual stream setup will happen in process() once connections are ready");

        Ok(())
    }

    fn teardown(&mut self) -> Result<()> {
        let device_name = self.device_info.as_ref().map(|d| d.name.as_str()).unwrap_or("Unknown");
        tracing::info!("AudioCapture {}: Stopping (captured {} frames)", device_name, self.frame_counter.load(Ordering::Relaxed));
        self._stream = None;
        self._device = None;
        Ok(())
    }

    // Business logic - called by macro-generated process()
    fn process(&mut self) -> Result<()> {
        // Pull mode: process() is called once to set up the stream, then cpal callback drives everything
        if !self.stream_setup_done {
            tracing::info!("[AudioCapture] process() called - setting up cpal stream now that connections are ready");
            self.setup_stream()?;
            self.stream_setup_done = true;
            tracing::info!("[AudioCapture] Stream setup complete, cpal callback will now drive audio capture");
            return Ok(());
        }

        // After setup, this processor is driven by cpal's audio callback thread
        // We don't do anything here - the callback fills the buffer and calls process_audio_callback()
        Ok(())
    }

    // Separate method for actual stream setup (called from process())
    fn setup_stream(&mut self) -> Result<()> {
        let host = cpal::default_host();

        // Find device by name or use default
        let device = if let Some(device_name_str) = &self.config.device_id {
            // Enumerate all input devices
            let devices: Vec<Device> = host
                .input_devices()
                .map_err(|e| StreamError::Configuration(format!("Failed to enumerate audio input devices: {}", e)))?
                .collect();

            // Try to find device by name
            devices
                .into_iter()
                .find(|d| {
                    if let Ok(name) = d.name() {
                        name == *device_name_str
                    } else {
                        false
                    }
                })
                .ok_or_else(|| StreamError::Configuration(format!("Audio input device '{}' not found", device_name_str)))?
        } else {
            // Use default input device when None
            host.default_input_device()
                .ok_or_else(|| StreamError::Configuration("No default audio input device".into()))?
        };

        let device_name = device
            .name()
            .unwrap_or_else(|_| "Unknown Device".to_string());

        // Get device's native configuration
        let default_config = device
            .default_input_config()
            .map_err(|e| StreamError::Configuration(format!("Failed to get audio config: {}", e)))?;

        self.device_sample_rate = default_config.sample_rate().0;
        self.device_channels = default_config.channels();

        tracing::info!(
            "Audio input device: {} (native: {}Hz, {} channels | runtime: {}Hz, {} samples buffer)",
            device_name,
            self.device_sample_rate,
            self.device_channels,
            self.runtime_sample_rate,
            self.runtime_buffer_size
        );

        // Log supported input configs for debugging
        tracing::info!("[AudioCapture] Checking device supported input configs...");
        if let Ok(mut configs) = device.supported_input_configs() {
            let mut count = 0;
            for config in configs.by_ref().take(5) {
                tracing::info!("[AudioCapture]   Supported config: {:?}", config);
                count += 1;
            }
            if count == 0 {
                tracing::warn!("[AudioCapture] No supported input configs found!");
            }
        } else {
            tracing::warn!("[AudioCapture] Failed to query supported input configs");
        }

        let device_info = AppleAudioInputDevice {
            id: 0,
            name: device_name.clone(),
            sample_rate: self.device_sample_rate,
            channels: self.device_channels as u32,
            is_default: self.config.device_id.is_none(),
        };

        let sample_buffer_clone = self.sample_buffer.clone();
        let audio_output_clone = self.audio.clone();
        let frame_counter_clone = self.frame_counter.clone();
        let runtime_sample_rate = self.runtime_sample_rate;
        let runtime_buffer_size = self.runtime_buffer_size;
        let device_sample_rate = self.device_sample_rate;
        let device_channels = self.device_channels;
        let resampler_clone = self.resampler.clone();

        // Use device's native configuration to avoid unsupported config errors
        // IMPORTANT: We must keep buffer_size as Default for input streams on macOS
        // Fixed buffer sizes can prevent the callback from being invoked
        let stream_config = StreamConfig {
            channels: self.device_channels,
            sample_rate: cpal::SampleRate(self.device_sample_rate),
            buffer_size: cpal::BufferSize::Default,
        };

        tracing::info!("[AudioCapture] About to build input stream...");
        tracing::info!("[AudioCapture] Stream config: {}Hz, {} channels, buffer_size: Default",
            self.device_sample_rate, self.device_channels);

        let stream = device
            .build_input_stream(
                &stream_config,
                move |data: &[f32], info: &cpal::InputCallbackInfo| {
                    // Temporarily use INFO level to diagnose callback invocation
                    tracing::info!("[AudioCapture Callback] *** INVOKED *** Received {} samples, timestamp: {:?}",
                        data.len(), info.timestamp());

                    // Add samples to buffer
                    {
                        let mut buffer = sample_buffer_clone.lock();
                        buffer.extend_from_slice(data);
                        tracing::debug!("[AudioCapture Callback] Buffer now has {} samples", buffer.len());
                    }

                    // Process accumulated samples and produce frames
                    Self::process_buffer_and_write_frames(
                        &sample_buffer_clone,
                        &audio_output_clone,
                        &frame_counter_clone,
                        runtime_sample_rate,
                        runtime_buffer_size,
                        device_sample_rate,
                        device_channels,
                        &resampler_clone,
                    );
                },
                move |err| {
                    tracing::error!("Audio capture error: {}", err);
                },
                None,
            )
            .map_err(|e| StreamError::Configuration(format!("Failed to build audio stream: {}", e)))?;

        tracing::info!("[AudioCapture] Input stream built successfully, calling play()...");

        stream
            .play()
            .map_err(|e| StreamError::Configuration(format!("Failed to start audio stream: {}", e)))?;

        tracing::info!("[AudioCapture] Stream.play() succeeded - stream is now active");
        tracing::info!("[AudioCapture] Stream object address: {:p}", &stream);
        tracing::info!("[AudioCapture] Storing stream in self._stream to keep it alive...");

        // Create resampler if sample rates differ (wrap in Arc<Mutex> for callback access)
        self.resampler = Arc::new(Mutex::new(if self.device_sample_rate != self.runtime_sample_rate {
            let params = SincInterpolationParameters {
                sinc_len: 256,
                f_cutoff: 0.95,
                interpolation: SincInterpolationType::Linear,
                oversampling_factor: 256,
                window: WindowFunction::BlackmanHarris2,
            };

            // Calculate input chunk size for SincFixedIn
            // SincFixedIn expects a fixed number of INPUT samples to produce OUTPUT samples
            let ratio = self.device_sample_rate as f64 / self.runtime_sample_rate as f64;
            let input_chunk_size = ((self.runtime_buffer_size as f64 * ratio).ceil() as usize).max(1);

            tracing::info!("[AudioCapture] Creating resampler: input_chunk_size={} samples → output={} samples (ratio={})",
                input_chunk_size, self.runtime_buffer_size, ratio);

            let resampler = SincFixedIn::<f32>::new(
                self.runtime_sample_rate as f64 / self.device_sample_rate as f64,
                2.0, // max relative ratio change
                params,
                input_chunk_size, // INPUT chunk size, not output!
                1, // mono channel
            ).map_err(|e| StreamError::Configuration(format!("Failed to create resampler: {}", e)))?;

            tracing::info!(
                "AudioCapture {}: Resampling enabled ({}Hz → {}Hz)",
                device_name,
                self.device_sample_rate,
                self.runtime_sample_rate
            );

            Some(resampler)
        } else {
            None
        }));

        self.device_info = Some(device_info);
        self._device = Some(device);
        self._stream = Some(stream);

        tracing::info!("[AudioCapture] {} Started - cpal stream is now running", device_name);
        tracing::info!("[AudioCapture] Device callback will asynchronously fill buffer and write frames");
        Ok(())
    }

    // Static helper method called from cpal callback to process accumulated audio samples
    fn process_buffer_and_write_frames(
        sample_buffer: &Arc<Mutex<Vec<f32>>>,
        audio_output: &StreamOutput<AudioFrame<1>>,
        frame_counter: &Arc<AtomicU64>,
        runtime_sample_rate: u32,
        runtime_buffer_size: usize,
        device_sample_rate: u32,
        device_channels: u16,
        resampler: &Arc<Mutex<Option<SincFixedIn<f32>>>>,
    ) {
        // This method chunks device samples to match runtime buffer size:
        // - If device buffer > runtime buffer: splits into multiple frames
        // - If device buffer < runtime buffer: accumulates until enough samples

        loop {
            // Step 1: Check if we have enough samples for one runtime buffer
            let device_samples = {
                let mut buffer = sample_buffer.lock();

                // Calculate how many device samples we need for one runtime buffer
                let samples_needed = if device_sample_rate == runtime_sample_rate {
                    runtime_buffer_size * device_channels as usize
                } else {
                    // Calculate required input samples for desired output samples
                    let ratio = device_sample_rate as f64 / runtime_sample_rate as f64;
                    ((runtime_buffer_size as f64 * ratio).ceil() as usize) * device_channels as usize
                };

                tracing::info!("[AudioCapture Processing] Buffer has {} samples, need {} (device: {}Hz {}ch, runtime: {}Hz {}samples)",
                    buffer.len(), samples_needed, device_sample_rate, device_channels, runtime_sample_rate, runtime_buffer_size);

                // Check if we have enough samples
                if buffer.len() < samples_needed {
                    // Not enough samples - wait for more from device callback
                    tracing::info!("[AudioCapture Processing] Not enough samples yet, waiting for more...");
                    return;
                }

                // Extract exactly what we need, leaving rest for next iteration
                tracing::info!("[AudioCapture Processing] Draining {} samples from buffer", samples_needed);
                buffer.drain(..samples_needed).collect::<Vec<f32>>()
            };

            // Step 2: Convert multi-channel to mono by averaging channels
            let mono_samples: Vec<f32> = if device_channels > 1 {
                device_samples.chunks_exact(device_channels as usize)
                    .map(|chunk| {
                        let sum: f32 = chunk.iter().sum();
                        sum / device_channels as f32
                    })
                    .collect()
            } else {
                device_samples
            };

            // Step 3: Resample if needed (device sample rate → runtime sample rate)
            let output_samples: Vec<f32> = if let Some(ref mut resampler_inner) = *resampler.lock() {
                // Use rubato for high-quality resampling
                let waves_in = vec![mono_samples];
                let waves_out = match resampler_inner.process(&waves_in, None) {
                    Ok(out) => out,
                    Err(e) => {
                        tracing::error!("[AudioCapture Callback] Resampling failed: {}", e);
                        return;
                    }
                };

                // Rubato should produce exactly runtime_buffer_size samples
                let mut output = waves_out[0].clone();

                // Ensure exact size (pad or truncate if needed due to rounding)
                output.resize(runtime_buffer_size, 0.0);
                output
            } else {
                // No resampling - ensure we have exactly runtime_buffer_size samples
                let mut output = mono_samples;
                output.resize(runtime_buffer_size, 0.0);
                output
            };

            // Step 4: Create and write frame
            let frame_number = frame_counter.fetch_add(1, Ordering::Relaxed);
            let timestamp_ns = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos() as i64;

            let frame = AudioFrame::<1>::new(
                output_samples.clone(),
                timestamp_ns,
                frame_number,
            );

            tracing::info!("[AudioCapture Processing] *** WRITING FRAME {} *** with {} samples", frame_number, output_samples.len());
            audio_output.write(frame);
            tracing::info!("[AudioCapture Processing] Frame {} written successfully", frame_number);

            // Check if we have enough samples for another frame
            // If yes, loop and produce another frame immediately
            // If no, return and wait for more samples
            let buffer_len = sample_buffer.lock().len();
            let samples_needed = if device_sample_rate == runtime_sample_rate {
                runtime_buffer_size * device_channels as usize
            } else {
                let ratio = device_sample_rate as f64 / runtime_sample_rate as f64;
                ((runtime_buffer_size as f64 * ratio).ceil() as usize) * device_channels as usize
            };

            if buffer_len < samples_needed {
                // Not enough for another frame - exit loop
                return;
            }
            // Otherwise, loop continues and produces another frame
        }
    }

    // Helper methods
    pub fn list_devices() -> Result<Vec<AppleAudioInputDevice>> {
        let host = cpal::default_host();
        let devices: Result<Vec<AppleAudioInputDevice>> = host
            .input_devices()
            .map_err(|e| StreamError::Configuration(format!("Failed to enumerate audio input devices: {}", e)))?
            .enumerate()
            .map(|(id, device)| {
                let name = device.name().unwrap_or_else(|_| "Unknown Device".to_string());

                let config = device
                    .default_input_config()
                    .map_err(|e| StreamError::Configuration(format!("Failed to get device config: {}", e)))?;

                let sample_rate = config.sample_rate().0;
                let channels = config.channels() as u32;

                let is_default = if let Some(default_device) = host.default_input_device() {
                    device.name().ok() == default_device.name().ok()
                } else {
                    false
                };

                Ok(AppleAudioInputDevice {
                    id,
                    name,
                    sample_rate,
                    channels,
                    is_default,
                })
            })
            .collect();

        devices
    }

    pub fn current_device(&self) -> Option<&AppleAudioInputDevice> {
        self.device_info.as_ref()
    }

    pub fn current_level(&self) -> f32 {
        *self.current_level.lock()
    }
}


#[cfg(test)]
mod tests {
    use super::*;
    use crate::core::traits::StreamProcessor;

    #[test]
    fn test_list_devices() {
        let devices = AppleAudioCaptureProcessor::list_devices();

        assert!(devices.is_ok());

        if let Ok(devices) = devices {
            println!("Found {} audio input devices:", devices.len());
            for device in &devices {
                println!(
                    "  [{}] {}: {}Hz, {} channels{}",
                    device.id,
                    device.name,
                    device.sample_rate,
                    device.channels,
                    if device.is_default { " (default)" } else { "" }
                );
            }

            assert!(devices.len() > 0, "Expected at least one audio input device");
        }
    }

    #[test]
    fn test_create_default_device() {
        let config = AppleAudioCaptureConfig {
            device_id: None,
        };

        let result = AppleAudioCaptureProcessor::from_config(config);

        match result {
            Ok(_processor) => {
                // Note: from_config() doesn't call setup(), so device_info and sample rates
                // are not yet initialized. This test just verifies that from_config() succeeds.
                println!("Successfully created audio capture processor from config");
            }
            Err(e) => {
                println!("Note: Could not create audio capture (may require permissions): {}", e);
            }
        }
    }

    #[test]
    fn test_capture_audio() {
        let config = AppleAudioCaptureConfig::default();
        let result = AppleAudioCaptureProcessor::from_config(config);

        if let Ok(mut processor) = result {
            std::thread::sleep(std::time::Duration::from_millis(100));

            let result = processor.process();
            if result.is_ok() {
                println!("Successfully processed captured audio");

                let level = processor.current_level();
                println!("Current audio level: {:.3}", level);
                assert!(level >= 0.0 && level <= 1.0);
            } else {
                println!("Note: Audio processing returned: {:?}", result);
            }
        } else {
            println!("Note: Could not create audio capture (may require permissions)");
        }
    }
}
