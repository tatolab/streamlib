use crate::core::frames::AudioFrame;
use crate::core::utils::audio_resample::{ResamplingQuality, StereoResampler};
use crate::core::{LinkInput, Result, StreamError};
use cpal::traits::StreamTrait;
use cpal::Stream;
use std::sync::{Arc, Mutex};
use streamlib_macros::Processor;

// Apple-specific configuration and device types
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize, Default)]
pub struct AppleAudioOutputConfig {
    pub device_id: Option<String>,
}

#[derive(Debug, Clone)]
pub struct AppleAudioDevice {
    pub id: usize,
    pub name: String,
    pub sample_rate: u32,
    pub channels: u32,
    pub is_default: bool,
}

/// Internal state for adaptive resampling (wraps shared StereoResampler)
struct ResamplerState {
    resampler: StereoResampler,
}

impl ResamplerState {
    /// Create a new resampler for stereo audio (2 channels)
    fn new(source_rate: u32, target_rate: u32, chunk_size: usize) -> Result<Self> {
        tracing::info!(
            "[AudioOutput Adaptive] Creating resampler: {}Hz â†’ {}Hz (chunk_size={})",
            source_rate,
            target_rate,
            chunk_size
        );

        // Use high-quality resampling for audio output (user-facing)
        let resampler = StereoResampler::new(
            source_rate,
            target_rate,
            chunk_size,
            ResamplingQuality::High,
        )?;

        Ok(Self { resampler })
    }

    /// Resample stereo audio from source rate to target rate
    /// Input: interleaved stereo [L,R,L,R,...]
    /// Output: interleaved stereo [L,R,L,R,...] at target rate
    fn resample(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        self.resampler.resample(input)
    }
}

#[derive(Processor)]
#[processor(
    mode = Pull,
    description = "Plays audio through speakers/headphones using CoreAudio",
    unsafe_send
)]
pub struct AppleAudioOutputProcessor {
    #[input(description = "Stereo audio frame to play through speakers")]
    audio: LinkInput<AudioFrame>,

    #[config]
    config: AppleAudioOutputConfig,

    // Runtime state fields - auto-detected (no attribute needed)
    device_id: Option<usize>,
    device_name: String,
    device_info: Option<AppleAudioDevice>,
    stream: Option<Stream>,
    stream_setup_done: bool,
    sample_rate: u32,
    channels: u32,
    buffer_size: usize,

    // Adaptive resampling state (shared with audio callback thread)
    // Mutex is necessary because cpal callback runs on separate thread
    resampler_state: Arc<Mutex<Option<ResamplerState>>>,
}

// SAFETY: cpal::Stream is not Send, but AppleAudioOutputProcessor is safe to send between threads
// because cpal streams handle thread-safety internally via platform audio APIs
// unsafe impl Send auto-generated by StreamProcessor macro with unsafe_send attribute

// Only business logic - all trait methods auto-generated by macro!
impl AppleAudioOutputProcessor {
    // Lifecycle - auto-detected by macro
    fn setup(&mut self, _ctx: &crate::core::RuntimeContext) -> Result<()> {
        self.device_id = self
            .config
            .device_id
            .as_ref()
            .and_then(|s| s.parse::<usize>().ok());
        tracing::info!(
            "AudioOutput: start() called (Pull mode - will query device for native config)"
        );
        Ok(())
    }

    fn teardown(&mut self) -> Result<()> {
        self.stream = None;
        tracing::info!("AudioOutput {}: Stopped", self.device_name);
        Ok(())
    }

    // Business logic - called by macro-generated process()
    fn process(&mut self) -> Result<()> {
        if self.stream_setup_done {
            return Ok(());
        }

        tracing::info!(
            "AudioOutput: process() called - setting up stream now that connections are wired"
        );

        // Query hardware device for native sample_rate and buffer_size
        use cpal::traits::{DeviceTrait, HostTrait};

        let host = cpal::default_host();
        let device = if let Some(id) = self.device_id {
            let devices: Vec<_> = host
                .output_devices()
                .map_err(|e| {
                    StreamError::Configuration(format!("Failed to enumerate audio devices: {}", e))
                })?
                .collect();
            devices
                .get(id)
                .ok_or_else(|| {
                    StreamError::Configuration(format!("Audio device {} not found", id))
                })?
                .clone()
        } else {
            host.default_output_device().ok_or_else(|| {
                StreamError::Configuration("No default audio output device".into())
            })?
        };

        let device_config = device.default_output_config().map_err(|e| {
            StreamError::Configuration(format!("Failed to get audio config: {}", e))
        })?;

        let device_sample_rate = device_config.sample_rate().0;
        let device_channels = device_config.channels() as u32;

        // Query the device's preferred buffer size
        let device_buffer_size = match device_config.buffer_size() {
            cpal::SupportedBufferSize::Range { min: _, max } => *max as usize,
            cpal::SupportedBufferSize::Unknown => 512, // Fallback to reasonable default
        };

        tracing::info!(
            "AudioOutput: Queried device config - {}Hz, {} channels, {} buffer size",
            device_sample_rate,
            device_channels,
            device_buffer_size
        );

        // Clone the port for the audio callback thread
        let audio_port = self.audio.clone();

        // Clone resampler state for the audio callback thread
        let resampler_state = Arc::clone(&self.resampler_state);

        tracing::info!("AudioOutput: Cloned audio port and resampler state for callback thread");

        tracing::info!("AudioOutput: Setting up adaptive audio output with cpal");

        // Buffer for accumulating frames when device wants larger buffers than we provide
        let mut frame_buffer: Vec<f32> = Vec::new();

        // Track first frame for logging
        let mut first_frame_logged = false;

        let setup = crate::apple::audio_utils::setup_audio_output(
            self.device_id,
            device_buffer_size,
            move |data: &mut [f32], _info: &cpal::OutputCallbackInfo| {
                // Adaptive audio output: handle sample rate conversion on-the-fly
                // This ensures audio plays at correct speed regardless of device sample rate

                while frame_buffer.len() < data.len() {
                    if let Some(audio_frame) = audio_port.read() {
                        // Check if resampling is needed
                        if audio_frame.sample_rate != device_sample_rate {
                            // Sample rate mismatch - need to resample
                            let mut resampler = resampler_state.lock().unwrap();

                            // Lazy initialize resampler on first frame with mismatched rate
                            if resampler.is_none() {
                                // Calculate chunk size based on audio frame size
                                let chunk_size = audio_frame.samples.len() / 2; // samples per channel

                                match ResamplerState::new(
                                    audio_frame.sample_rate,
                                    device_sample_rate,
                                    chunk_size,
                                ) {
                                    Ok(state) => {
                                        tracing::info!(
                                            "[AudioOutput Adaptive] ðŸ”„ Resampler initialized: {}Hz â†’ {}Hz",
                                            audio_frame.sample_rate,
                                            device_sample_rate
                                        );
                                        *resampler = Some(state);
                                    }
                                    Err(e) => {
                                        tracing::error!(
                                            "[AudioOutput Adaptive] âŒ Failed to create resampler: {}",
                                            e
                                        );
                                        // Fall through to direct copy (will play at wrong speed)
                                    }
                                }
                            }

                            // Resample if we have a resampler
                            if let Some(ref mut state) = *resampler {
                                match state.resample(&audio_frame.samples) {
                                    Ok(resampled) => {
                                        if !first_frame_logged {
                                            tracing::info!(
                                                "[AudioOutput Adaptive] ðŸ”„ First frame resampled: {} input samples â†’ {} output samples ({}Hz â†’ {}Hz)",
                                                audio_frame.samples.len(),
                                                resampled.len(),
                                                audio_frame.sample_rate,
                                                device_sample_rate
                                            );
                                            first_frame_logged = true;
                                        }
                                        frame_buffer.extend_from_slice(&resampled);
                                    }
                                    Err(e) => {
                                        tracing::error!(
                                            "[AudioOutput Adaptive] Resampling failed: {}",
                                            e
                                        );
                                        // Fallback: use original samples (wrong speed)
                                        frame_buffer.extend_from_slice(&audio_frame.samples);
                                    }
                                }
                            } else {
                                // No resampler available - use samples directly (wrong speed)
                                frame_buffer.extend_from_slice(&audio_frame.samples);
                            }
                        } else {
                            // Sample rates match - direct copy (no resampling needed)
                            if !first_frame_logged {
                                tracing::info!(
                                    "[AudioOutput Adaptive] âœ… Sample rates match ({}Hz) - no resampling needed",
                                    audio_frame.sample_rate
                                );
                                first_frame_logged = true;
                            }
                            frame_buffer.extend_from_slice(&audio_frame.samples);
                        }
                    } else {
                        // No more frames available - break and use what we have
                        break;
                    }
                }

                if frame_buffer.len() >= data.len() {
                    // We have enough data - copy and remove from buffer
                    data.copy_from_slice(&frame_buffer[..data.len()]);
                    frame_buffer.drain(..data.len());
                } else if !frame_buffer.is_empty() {
                    // We have some data but not enough - copy what we have and pad with silence
                    let copy_len = frame_buffer.len();
                    data[..copy_len].copy_from_slice(&frame_buffer);
                    data[copy_len..].fill(0.0);
                    frame_buffer.clear();
                } else {
                    // No data at all - output silence
                    data.fill(0.0);
                }
            },
        )?;

        tracing::info!("AudioOutput: Starting cpal stream playback");
        setup
            .stream
            .play()
            .map_err(|e| StreamError::Configuration(format!("Failed to start stream: {}", e)))?;

        tracing::info!("AudioOutput: cpal stream.play() succeeded");

        self.stream = Some(setup.stream);
        self.device_name = setup.device_info.name.clone();
        self.device_info = Some(setup.device_info);
        self.sample_rate = setup.sample_rate;
        self.channels = setup.channels;
        self.buffer_size = device_buffer_size;
        self.stream_setup_done = true;

        tracing::info!(
            "AudioOutput {}: Stream setup complete ({}Hz, {} channels, {} buffer size, Pull mode)",
            self.device_name,
            self.sample_rate,
            self.channels,
            self.buffer_size
        );

        Ok(())
    }
}
