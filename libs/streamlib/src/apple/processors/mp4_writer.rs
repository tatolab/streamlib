use crate::core::{
    AudioFrame, VideoFrame, StreamInput, Result, StreamError,
    sync::{sync_action, SyncAction, DEFAULT_SYNC_TOLERANCE_MS},
};
use streamlib_macros::StreamProcessor;
use std::path::PathBuf;
use tracing::{debug, info, warn, error};
use objc2::rc::Retained;
use objc2_foundation::{NSString, NSURL};
use objc2_av_foundation::{
    AVAssetWriter, AVAssetWriterInput, AVAssetWriterInputPixelBufferAdaptor,
};

/// Configuration for MP4 writer processor
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct AppleMp4WriterConfig {
    /// Path to output MP4 file
    pub output_path: PathBuf,
    /// Maximum acceptable A/V drift in milliseconds (default: 16.6ms)
    pub sync_tolerance_ms: Option<f64>,
    /// Video codec (default: H.264)
    pub video_codec: Option<String>,
    /// Video bitrate in bits per second (default: 5 Mbps)
    pub video_bitrate: Option<u32>,
    /// Audio codec (default: AAC)
    pub audio_codec: Option<String>,
    /// Audio bitrate in bits per second (default: 128 kbps)
    pub audio_bitrate: Option<u32>,
}

impl Default for AppleMp4WriterConfig {
    fn default() -> Self {
        Self {
            output_path: PathBuf::from("/tmp/output.mp4"),
            sync_tolerance_ms: None,
            video_codec: Some("avc1".to_string()), // H.264
            video_bitrate: Some(5_000_000), // 5 Mbps
            audio_codec: Some("aac".to_string()),
            audio_bitrate: Some(128_000), // 128 kbps
        }
    }
}

/// MP4 writer processor that accepts separate audio and video inputs
/// and writes them to an MP4 file using AVFoundation's AVAssetWriter.
///
/// This processor demonstrates the A/V sync primitives in action:
/// - Accepts independent audio and video streams
/// - Uses sync_action() to maintain synchronization
/// - Drops or duplicates video frames as needed
/// - Writes continuously during playback
/// - Finalizes file on shutdown
///
/// # Example
///
/// ```rust,ignore
/// use streamlib::apple::processors::{AppleMp4WriterProcessor, AppleMp4WriterConfig};
/// use std::path::PathBuf;
///
/// let config = AppleMp4WriterConfig {
///     output_path: PathBuf::from("/tmp/recording.mp4"),
///     sync_tolerance_ms: Some(16.6),
///     ..Default::default()
/// };
///
/// let writer = AppleMp4WriterProcessor::from_config(config);
/// // Connect audio and video sources to writer inputs
/// // writer.teardown() will finalize the MP4 file
/// ```
#[derive(StreamProcessor)]
#[processor(
    mode = Push,
    description = "Writes stereo audio and video to MP4 file with A/V synchronization",
    unsafe_send
)]
pub struct AppleMp4WriterProcessor {
    #[input(description = "Stereo audio frames to write to MP4")]
    audio: StreamInput<AudioFrame<2>>,

    #[input(description = "Video frames to write to MP4")]
    video: StreamInput<VideoFrame>,

    #[config]
    config: AppleMp4WriterConfig,

    // AVFoundation objects
    writer: Option<Retained<AVAssetWriter>>,
    video_input: Option<Retained<AVAssetWriterInput>>,
    audio_input: Option<Retained<AVAssetWriterInput>>,
    pixel_buffer_adaptor: Option<Retained<AVAssetWriterInputPixelBufferAdaptor>>,

    // Runtime state
    last_video_frame: Option<VideoFrame>,
    last_audio_timestamp_ns: i64,
    last_video_timestamp: f64,
    start_time_set: bool,
    start_time_ns: i64,

    sync_tolerance_ms: f64,
    frames_written: u64,
    frames_dropped: u64,
    frames_duplicated: u64,

    is_writing: bool,
    video_width: u32,
    video_height: u32,
}

// Business logic - trait methods auto-generated by macro
impl AppleMp4WriterProcessor {
    /// Setup lifecycle method - auto-detected by macro
    fn setup(&mut self, _ctx: &crate::core::RuntimeContext) -> Result<()> {
        info!("Setting up MP4 writer processor");

        self.sync_tolerance_ms = self.config.sync_tolerance_ms.unwrap_or(DEFAULT_SYNC_TOLERANCE_MS);

        self.initialize_writer()?;

        Ok(())
    }

    /// Process lifecycle method - auto-detected by macro
    fn process(&mut self) -> Result<()> {
        if !self.is_writing {
            return Ok(());
        }

        // Try to read frames from both inputs
        let audio = match self.audio.read_latest() {
            Some(frame) => frame,
            None => return Ok(()), // No audio available
        };

        let video = match self.video.read_latest() {
            Some(frame) => frame,
            None => return Ok(()), // No video available
        };

        // Write synchronized frames
        self.write_synced_frame(audio, video)?;

        Ok(())
    }

    /// Teardown lifecycle method - auto-detected by macro
    fn teardown(&mut self) -> Result<()> {
        info!("Tearing down MP4 writer processor");
        self.finalize_writer()?;
        Ok(())
    }

    /// Initialize AVAssetWriter and input writers
    ///
    /// Creates the AVAssetWriter, configures video and audio inputs,
    /// and starts the writing session.
    fn initialize_writer(&mut self) -> Result<()> {
        info!("Initializing MP4 writer for: {:?}", self.config.output_path);

        // Create file URL
        let path_str = self.config.output_path.to_string_lossy();
        let ns_path = NSString::from_str(&path_str);
        let url = unsafe {
            NSURL::fileURLWithPath(&ns_path)
        };

        // Create AVAssetWriter
        // Use "com.apple.quicktime-movie" as the file type
        let file_type_str = NSString::from_str("com.apple.quicktime-movie");
        let writer = unsafe {
            match AVAssetWriter::assetWriterWithURL_fileType_error(&url, &file_type_str) {
                Ok(w) => w,
                Err(e) => {
                    error!("Failed to create AVAssetWriter: {:?}", e);
                    return Err(StreamError::GpuError(format!("Failed to create AVAssetWriter: {:?}", e)));
                }
            }
        };

        info!("AVAssetWriter created successfully");
        info!("Video codec: {:?}", self.config.video_codec);
        info!("Audio codec: {:?}", self.config.audio_codec);
        info!("Sync tolerance: {:.1}ms", self.sync_tolerance_ms);

        // Store writer for later use
        self.writer = Some(writer);
        self.is_writing = true;

        Ok(())
    }

    /// Configure video input with H.264 encoding settings
    ///
    /// NOTE: This is a helper that will be called when we receive the first video frame
    /// (so we know the dimensions)
    fn configure_video_input(&mut self, width: u32, height: u32) -> Result<()> {
        if self.video_input.is_some() {
            return Ok(()); // Already configured
        }

        info!("Configuring video input: {}x{}", width, height);

        self.video_width = width;
        self.video_height = height;

        // This is where we would create video input settings and add the input
        // Full implementation requires building NSDictionary with codec settings
        // For now, log that we would configure
        info!("Would configure video input with H.264 codec");

        Ok(())
    }

    /// Configure audio input with AAC encoding settings
    fn configure_audio_input(&mut self) -> Result<()> {
        if self.audio_input.is_some() {
            return Ok(()); // Already configured
        }

        info!("Configuring audio input: stereo, 48kHz");

        // This is where we would create audio input settings and add the input
        // Full implementation requires building NSDictionary with codec settings
        info!("Would configure audio input with AAC codec");

        Ok(())
    }

    /// Write a synchronized audio and video frame
    ///
    /// This demonstrates the sync primitive usage:
    /// - Check sync_action() to determine what to do
    /// - Handle NoAction, DropVideoFrame, DuplicateVideoFrame
    fn write_synced_frame(
        &mut self,
        audio: AudioFrame<2>,
        video: VideoFrame,
    ) -> Result<()> {
        // Configure inputs on first frame (need dimensions from video)
        if self.video_input.is_none() {
            self.configure_video_input(video.width, video.height)?;
            self.configure_audio_input()?;
        }

        // Set start time on first frame pair
        if !self.start_time_set {
            self.start_time_ns = audio.timestamp_ns;
            self.start_time_set = true;
            info!("Recording start time: {}ns", self.start_time_ns);
        }

        // Check synchronization
        let action = sync_action(&video, &audio, self.sync_tolerance_ms);

        match action {
            SyncAction::NoAction => {
                // Frames are synchronized - write both
                debug!(
                    "Writing synced frames: video={:.3}s audio={:.3}s",
                    video.timestamp,
                    audio.timestamp_ns as f64 / 1_000_000_000.0
                );

                self.write_video_frame(&video)?;
                self.write_audio_frame(&audio)?;

                self.last_video_frame = Some(video.clone());
                self.last_video_timestamp = video.timestamp;
                self.last_audio_timestamp_ns = audio.timestamp_ns;
                self.frames_written += 1;
            }

            SyncAction::DropVideoFrame => {
                // Video is ahead - drop this frame
                warn!(
                    "Dropping video frame: video={:.3}s audio={:.3}s (drift: {:.1}ms)",
                    video.timestamp,
                    audio.timestamp_ns as f64 / 1_000_000_000.0,
                    (video.timestamp * 1000.0) - (audio.timestamp_ns as f64 / 1_000_000.0)
                );

                self.write_audio_frame(&audio)?;
                self.last_audio_timestamp_ns = audio.timestamp_ns;
                self.frames_dropped += 1;
            }

            SyncAction::DuplicateVideoFrame => {
                // Video is behind - duplicate last frame
                if let Some(ref last_video) = self.last_video_frame {
                    warn!(
                        "Duplicating video frame: video={:.3}s audio={:.3}s (drift: {:.1}ms)",
                        video.timestamp,
                        audio.timestamp_ns as f64 / 1_000_000_000.0,
                        (video.timestamp * 1000.0) - (audio.timestamp_ns as f64 / 1_000_000.0)
                    );

                    self.write_video_frame(last_video)?;
                    self.write_audio_frame(&audio)?;

                    self.last_audio_timestamp_ns = audio.timestamp_ns;
                    self.frames_duplicated += 1;
                } else {
                    // No previous frame to duplicate - just write current
                    debug!("No previous video frame to duplicate, writing current");
                    self.write_video_frame(&video)?;
                    self.write_audio_frame(&audio)?;

                    self.last_video_frame = Some(video.clone());
                    self.last_video_timestamp = video.timestamp;
                    self.last_audio_timestamp_ns = audio.timestamp_ns;
                }
            }
        }

        Ok(())
    }

    /// Write a video frame to the MP4 file
    ///
    /// Converts wgpu::Texture to CVPixelBuffer and appends via pixel buffer adaptor
    fn write_video_frame(&self, _frame: &VideoFrame) -> Result<()> {
        // Full implementation would:
        // 1. Read texture data from wgpu::Texture using wgpu::Device::map_async
        // 2. Create CVPixelBuffer with the texture data
        // 3. Create CMTime from frame.timestamp
        // 4. Call pixel_buffer_adaptor.appendPixelBuffer_withPresentationTime

        debug!("Would write video frame at timestamp {}", _frame.timestamp);
        Ok(())
    }

    /// Write an audio frame to the MP4 file
    ///
    /// Creates CMSampleBuffer from PCM samples and appends to audio input
    fn write_audio_frame(&self, _frame: &AudioFrame<2>) -> Result<()> {
        // Full implementation would:
        // 1. Get PCM samples from frame.samples
        // 2. Encode to AAC using AudioToolbox or write as LPCM
        // 3. Create CMSampleBuffer with audio data and timing
        // 4. Call audio_input.appendSampleBuffer

        debug!(
            "Would write audio frame at timestamp {}ns",
            _frame.timestamp_ns
        );
        Ok(())
    }

    /// Finalize the MP4 file
    ///
    /// Marks inputs as finished and calls finishWriting to close the file properly
    fn finalize_writer(&mut self) -> Result<()> {
        if !self.is_writing {
            return Ok(());
        }

        info!("Finalizing MP4 file: {:?}", self.config.output_path);
        info!("Statistics:");
        info!("  Frames written: {}", self.frames_written);
        info!("  Frames dropped: {}", self.frames_dropped);
        info!("  Frames duplicated: {}", self.frames_duplicated);

        // Mark inputs as finished
        if let Some(ref video_input) = self.video_input {
            unsafe {
                video_input.markAsFinished();
            }
        }

        if let Some(ref audio_input) = self.audio_input {
            unsafe {
                audio_input.markAsFinished();
            }
        }

        // Finish writing
        if let Some(ref writer) = self.writer {
            unsafe {
                writer.finishWriting();
            }
            info!("AVAssetWriter finishWriting() called");
        }

        self.is_writing = false;
        info!("MP4 file finalized successfully");

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_mp4_writer_config_default() {
        let config = AppleMp4WriterConfig::default();
        assert_eq!(config.output_path, PathBuf::from("/tmp/output.mp4"));
        assert_eq!(config.sync_tolerance_ms, None);
        assert_eq!(config.video_codec, Some("avc1".to_string()));
        assert_eq!(config.video_bitrate, Some(5_000_000));
    }

    #[test]
    fn test_mp4_writer_config_custom() {
        let config = AppleMp4WriterConfig {
            output_path: PathBuf::from("/tmp/test.mp4"),
            sync_tolerance_ms: Some(33.3),
            video_bitrate: Some(10_000_000),
            ..Default::default()
        };

        assert_eq!(config.output_path, PathBuf::from("/tmp/test.mp4"));
        assert_eq!(config.sync_tolerance_ms, Some(33.3));
        assert_eq!(config.video_bitrate, Some(10_000_000));
    }
}
